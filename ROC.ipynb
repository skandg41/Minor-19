{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ROC.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skandg41/Minor-19/blob/master/ROC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdTP01Ex1ikD",
        "colab_type": "text"
      },
      "source": [
        "# ***Defining the image call***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFuibKU911Ty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "     // await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 1, 1);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVSSMZpZ3Slw",
        "colab_type": "text"
      },
      "source": [
        "# ***Defining Camera capture function***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkX6zjlD3cx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "def capture():\n",
        "  try:\n",
        "    filename = take_photo()\n",
        "    #print('Saved to {}'.format(filename))\n",
        "\n",
        "    # Show the image which was just taken.\n",
        "    #display(Image(filename))\n",
        "  except Exception as err:\n",
        "    # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "    # grant the page permission to access it.\n",
        "    print(str(err))\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUUg4LMi3ic4",
        "colab_type": "text"
      },
      "source": [
        "# ***Applying ML Concepts***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_etxIlc3sE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import mrcnn.config\n",
        "import mrcnn.utils\n",
        "from mrcnn.model import MaskRCNN\n",
        "from pathlib import Path\n",
        "from twilio.rest import Client\n",
        "from google.colab.patches import cv2_imshow\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Configuration that will be used by the Mask-RCNN library\n",
        "class MaskRCNNConfig(mrcnn.config.Config):\n",
        "    NAME = \"coco_pretrained_model_config\"\n",
        "    IMAGES_PER_GPU = 1\n",
        "    GPU_COUNT = 1\n",
        "    NUM_CLASSES = 1 + 80  # COCO dataset has 80 classes + one background class\n",
        "    DETECTION_MIN_CONFIDENCE = 0.6\n",
        "\n",
        "# Filter a list of Mask R-CNN detection results to get only the detected cars / trucks\n",
        "def get_car_boxes(boxes, class_ids):\n",
        "    car_boxes = []\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        # If the detected object isn't a car / truck, skip it\n",
        "        if class_ids[i] in [3, 8, 6]:\n",
        "            car_boxes.append(box)\n",
        "\n",
        "    return np.array(car_boxes)\n",
        "\n",
        "# Twilio config\n",
        "twilio_account_sid = 'AC5a5765e9993784b49fb36e159b361a58'\n",
        "twilio_auth_token = '75baf4ecffaa52f0e191c6e0601215d5'\n",
        "# twilio_phone_number = '+19283160580'\n",
        "# destination_phone_number = '+919630422794'\n",
        "client = Client(twilio_account_sid, twilio_auth_token)\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = Path(\".\")\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    mrcnn.utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
        "\n",
        "# Video file or camera to process \n",
        "#VIDEO_SOURCE = \"content/Parking.mp4\"\n",
        "\n",
        "# Create a Mask-RCNN model in inference mode\n",
        "model = MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=MaskRCNNConfig())\n",
        "\n",
        "# Load pre-trained model\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "\n",
        "# Location of parking spaces\n",
        "parked_car_boxes = None\n",
        "\n",
        "# Load the video file we want to run detection on\n",
        "#video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "try: \n",
        "      \n",
        "    # creating a folder named data \n",
        "    if not os.path.exists('data'): \n",
        "        os.makedirs('data') \n",
        "        \n",
        "# if not created then raise error \n",
        "except OSError: \n",
        "    print ('Error: Creating directory of data') \n",
        "    \n",
        "# How many frames of video we've seen in a row with a parking space open\n",
        "free_space_frames = 0\n",
        "\n",
        "# Have we sent an SMS alert yet?\n",
        "sms_sent = False\n",
        "# Loop over each frame of video\n",
        "while (True):\n",
        "\n",
        "    capture()\n",
        "    video_capture = cv2.VideoCapture(\"photo.jpg\")\n",
        "    success,frame = video_capture.read()\n",
        "    \n",
        "    #print (success)\n",
        "    #print (frame)\n",
        "    \n",
        "    # Read the video from specified path \n",
        "# cam = cv2.VideoCapture(\"Editedpark.mp4\") \n",
        "    \n",
        "    if not success:\n",
        "      break\n",
        "    # Convert the image from BGR color (which OpenCV uses) to RGB color\n",
        "    rgb_image = frame[:, :, ::-1]\n",
        "    \n",
        "    # Run the image through the Mask R-CNN model to get results.\n",
        "    results = model.detect([rgb_image], verbose=0)\n",
        "    # Mask R-CNN assumes we are running detection on multiple images.\n",
        "    # We only passed in one image to detect, so only grab the first result.\n",
        "    r = results[0]\n",
        "    # The r variable will now have the results of detection:\n",
        "    # - r['rois'] are the bounding box of each detected object\n",
        "    # - r['class_ids'] are the class id (type) of each detected object\n",
        "    # - r['scores'] are the confidence scores for each detection\n",
        "    # - r['masks'] are the object masks for each detected object (which gives you the object outline)\n",
        "\n",
        "    if parked_car_boxes is None:\n",
        "        # This is the first frame of video - assume all the cars detected are in parking spaces.\n",
        "        # Save the location of each car as a parking space box and go to the next frame of video.\n",
        "        parked_car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
        "    else:\n",
        "        # We already know where the parking spaces are. Check if any are currently unoccupied.\n",
        "\n",
        "        # Get where cars are currently located in the frame\n",
        "        car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
        "\n",
        "        # See how much those cars overlap with the known parking spaces\n",
        "        overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes)\n",
        "        # Assume no spaces are free until we find one that is free\n",
        "        free_space = False\n",
        "        # Loop through each known parking space box\n",
        "        for parking_area, overlap_areas in zip(parked_car_boxes, overlaps):\n",
        "\n",
        "            # For this parking space, find the max amount it was covered by any\n",
        "            # car that was detected in our image (doesn't really matter which car)\n",
        "            max_IoU_overlap = np.max(overlap_areas)\n",
        "\n",
        "            # Get the top-left and bottom-right coordinates of the parking area\n",
        "            y1, x1, y2, x2 = parking_area\n",
        "            # Check if the parking space is occupied by seeing if any car overlaps\n",
        "            # it by more than 0.15 using IoU\n",
        "            if max_IoU_overlap < 0.15:\n",
        "                # Parking space not occupied! Draw a green box around it\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "                # Flag that we have seen at least one open space\n",
        "                free_space = True\n",
        "            else:\n",
        "                # Parking space is still occupied - draw a red box around it\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
        "            # Write the IoU measurement inside the box\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, f\"{max_IoU_overlap:0.2}\", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255))\n",
        "        # If at least one space was free, start counting frames\n",
        "        # This is so we don't alert based on one frame of a spot being open.\n",
        "        # This helps prevent the script triggered on one bad detection.\n",
        "        if free_space:\n",
        "            free_space_frames += 1\n",
        "        else:\n",
        "            # If no spots are free, reset the count\n",
        "            free_space_frames = 0\n",
        "        # If a space has been free for several frames, we are pretty sure it is really free!\n",
        "        if free_space_frames > 10:\n",
        "            # Write SPACE AVAILABLE!! at the top of the screen\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, f\"SPACE AVAILABLE!\", (10, 150), font, 3.0, (0, 255, 0), 2, cv2.FILLED)\n",
        "            # If we haven't sent an SMS yet, sent it!\n",
        "            if not sms_sent:\n",
        "              print(\"SENDING SMS!!!\")\n",
        "              message = client.messages.create(\n",
        "                body=\"Parking space open - go go go!\",\n",
        "                from_='+19283160580',\n",
        "                to='+919630422794'\n",
        "                  )\n",
        "              sms_sent = True\n",
        "\n",
        "        # Show the frame of video on the screen\n",
        "        plt.imshow(frame)\n",
        "        plt.show()\n",
        "       \n",
        "      # cv2.imshow('Video', frame)\n",
        "      # Hit 'q' to quit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "# Clean up everything when finished\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1qiKuwS3xGv",
        "colab_type": "text"
      },
      "source": [
        "# Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h08zMll33P6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mrcnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RGXcInj4or-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install twilio"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQHu36sa4sGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}